{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":24286,"databundleVersionId":1878097,"sourceType":"competition"},{"sourceId":9997048,"sourceType":"datasetVersion","datasetId":6152995}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install necessary packages (skip this if packages are already available in Kaggle environment)\n!pip install torch torchvision numpy scikit-learn\n!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118","metadata":{"_uuid":"1ab3b1e0-e207-4478-8a09-f315e47d9114","_cell_guid":"a43dfbba-fe90-425a-8476-57ddeeba8cb8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-24T06:41:39.380790Z","iopub.execute_input":"2024-11-24T06:41:39.381253Z","iopub.status.idle":"2024-11-24T06:41:55.852038Z","shell.execute_reply.started":"2024-11-24T06:41:39.381208Z","shell.execute_reply":"2024-11-24T06:41:55.851150Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms, models\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport random\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\n# Load the CSV file\ntrain_df = pd.read_csv(\"/kaggle/input/shopee-product-matching/train.csv\")\n\n# Base directory where images are stored\nimage_folder = \"/kaggle/input/shopee-product-matching/train_images/\"\n# Add a column with the full image paths\ntrain_df['image_path'] = train_df['image'].apply(lambda x: f\"{image_folder}{x}\")\n\ntrain_df.head()  # Display first few rows to verify data","metadata":{"_uuid":"26a562b9-864e-4b4f-bcb6-3f9f0264048c","_cell_guid":"d414a6ad-29cf-42d9-8354-5f48306fb3c3","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-24T06:41:55.854640Z","iopub.execute_input":"2024-11-24T06:41:55.855549Z","iopub.status.idle":"2024-11-24T06:41:55.980885Z","shell.execute_reply.started":"2024-11-24T06:41:55.855502Z","shell.execute_reply":"2024-11-24T06:41:55.980071Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to precompute negatives for each group\ndef precompute_negatives(df):\n    all_images = df['image_path'].tolist()\n    negatives = {}\n    grouped = df.groupby('label_group')\n    for group_id, group in grouped:\n        group_images = group['image_path'].tolist()\n        negatives[group_id] = [img for img in all_images if img not in group_images]\n    return negatives\n\n# Generate triplets function\ndef generate_triplets_paths_only(df, negative_pool):\n    triplets = []\n    grouped = df.groupby('label_group')\n\n    for group_id, group in tqdm(grouped, desc=\"Generating Triplets\"):\n        images = group['image_path'].tolist()\n        if len(images) < 2:\n            continue\n\n        for i in range(len(images)):\n            anchor = images[i]\n            positive = random.choice([img for img in images if img != anchor])\n            negative = random.choice(negative_pool[group_id])  # Select negative from precomputed pool\n            triplets.append((anchor, positive, negative))\n    \n    return triplets","metadata":{"_uuid":"a29a784a-4d21-4988-a5d8-2db3ccfd9f2f","_cell_guid":"435f3cfd-e098-4a0f-8ae3-e44a88def4d7","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-24T06:41:55.982164Z","iopub.execute_input":"2024-11-24T06:41:55.982498Z","iopub.status.idle":"2024-11-24T06:41:55.989221Z","shell.execute_reply.started":"2024-11-24T06:41:55.982471Z","shell.execute_reply":"2024-11-24T06:41:55.988354Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define augmentation and normalization pipelines\naugmentation_pipeline = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.5),  # Add vertical flips\n    transforms.RandomRotation(20),        # Increase rotation variability\n    transforms.RandomResizedCrop(size=(224, 224), scale=(0.6, 1.0)),  # Wider scaling\n    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),  # Stronger jitter\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n\n# No-op normalization pipeline (used for un-augmented images)\nno_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])","metadata":{"_uuid":"647f2c38-7061-4336-8019-6d510787e2f8","_cell_guid":"8d7198f3-3321-41db-894a-832c08ecd8d8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-24T06:41:55.990215Z","iopub.execute_input":"2024-11-24T06:41:55.990546Z","iopub.status.idle":"2024-11-24T06:41:56.003526Z","shell.execute_reply.started":"2024-11-24T06:41:55.990521Z","shell.execute_reply":"2024-11-24T06:41:56.002897Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to transform a single triplet with a probability of augmentation\ndef transform_triplet(triplet, augment_prob=0.5):\n    anchor, positive, negative = triplet\n\n    def apply_transform(img_path):\n        img = Image.open(img_path).convert(\"RGB\")\n        if random.random() < augment_prob:  # Apply augmentation with given probability\n            return augmentation_pipeline(img)\n        else:  # Apply only the no-op normalization\n            return no_transform(img)\n\n    # Apply transformations to each image in the triplet\n    anchor_img = apply_transform(anchor)\n    positive_img = apply_transform(positive)\n    negative_img = apply_transform(negative)\n\n    return anchor_img, positive_img, negative_img","metadata":{"_uuid":"86dcaf15-4d8b-45b6-a802-2baa56056de4","_cell_guid":"1ef83b1d-29d0-4f64-b064-0a480d492058","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-24T06:41:56.005277Z","iopub.execute_input":"2024-11-24T06:41:56.005639Z","iopub.status.idle":"2024-11-24T06:41:56.018889Z","shell.execute_reply.started":"2024-11-24T06:41:56.005614Z","shell.execute_reply":"2024-11-24T06:41:56.018091Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TripletPathsDataset(Dataset):\n    def __init__(self, triplets, augment_prob=0.5):\n        self.triplets = triplets\n        self.augment_prob = augment_prob\n\n    def __len__(self):\n        return len(self.triplets)\n\n    def __getitem__(self, idx):\n        return transform_triplet(self.triplets[idx], augment_prob=self.augment_prob)","metadata":{"_uuid":"7349b3e1-33fd-4075-a5ed-4ccbcfe859c5","_cell_guid":"2716e84f-70c6-4ca4-8707-b8007ae43e44","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-24T06:41:56.019880Z","iopub.execute_input":"2024-11-24T06:41:56.020123Z","iopub.status.idle":"2024-11-24T06:41:56.030774Z","shell.execute_reply.started":"2024-11-24T06:41:56.020099Z","shell.execute_reply":"2024-11-24T06:41:56.030026Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def visualize_triplet(triplet):\n    anchor, positive, negative = triplet\n\n    def to_image(tensor):\n        return tensor.permute(1, 2, 0).numpy()\n\n    fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n    ax[0].imshow(to_image(anchor))\n    ax[0].set_title(\"Anchor\")\n    ax[1].imshow(to_image(positive))\n    ax[1].set_title(\"Positive\")\n    ax[2].imshow(to_image(negative))\n    ax[2].set_title(\"Negative\")\n    \n    for a in ax:\n        a.axis(\"off\")\n    plt.show()","metadata":{"_uuid":"01678dfc-77cf-4f9e-a54d-ddcfb79aab91","_cell_guid":"f02e0066-5ea0-4799-9ef4-c781e7e90c6f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-24T06:41:56.031945Z","iopub.execute_input":"2024-11-24T06:41:56.032596Z","iopub.status.idle":"2024-11-24T06:41:56.041485Z","shell.execute_reply.started":"2024-11-24T06:41:56.032558Z","shell.execute_reply":"2024-11-24T06:41:56.040807Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Get unique label groups\nlabel_groups = train_df['label_group'].unique()\n\n# Split label groups into train and validation (80-20 split)\ntrain_groups, val_groups = train_test_split(label_groups, test_size=0.2, random_state=42)\n\n# Create train and validation DataFrames\ntrain_df_split = train_df[train_df['label_group'].isin(train_groups)].reset_index(drop=True)\nval_df_split = train_df[train_df['label_group'].isin(val_groups)].reset_index(drop=True)\n\nprint(f\"Training groups: {len(train_groups)}, Validation groups: {len(val_groups)}\")\nprint(f\"Training samples: {len(train_df_split)}, Validation samples: {len(val_df_split)}\")","metadata":{"_uuid":"2fc54f04-6521-4867-b7db-379d1773f35f","_cell_guid":"801b92be-89bb-4fac-8b3e-b09386d74182","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-24T06:41:56.042663Z","iopub.execute_input":"2024-11-24T06:41:56.043305Z","iopub.status.idle":"2024-11-24T06:41:56.083892Z","shell.execute_reply.started":"2024-11-24T06:41:56.043268Z","shell.execute_reply":"2024-11-24T06:41:56.082981Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Precompute negatives for training and validation\ntrain_negatives = precompute_negatives(train_df_split)\nval_negatives = precompute_negatives(val_df_split)\n\n# Generate training triplets\ntrain_triplets = generate_triplets_paths_only(train_df_split, train_negatives)\n\n# Generate validation triplets\nval_triplets = generate_triplets_paths_only(val_df_split, val_negatives)\n\nprint(f\"Generated {len(train_triplets)} training triplets\")\nprint(f\"Generated {len(val_triplets)} validation triplets\")","metadata":{"_uuid":"1907b180-edce-4f08-a2fc-8fb24a19aeb7","_cell_guid":"3b43af77-595b-4181-851f-da4a8ef6cfec","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-24T06:41:56.084877Z","iopub.execute_input":"2024-11-24T06:41:56.085118Z","iopub.status.idle":"2024-11-24T06:42:26.898595Z","shell.execute_reply.started":"2024-11-24T06:41:56.085094Z","shell.execute_reply":"2024-11-24T06:42:26.897748Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training dataset with augmentation\ntrain_dataset = TripletPathsDataset(train_triplets, augment_prob=0.5)\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=128,  # Larger batch size\n    shuffle=True,\n    num_workers=8,  # Use multiple CPU workers\n    pin_memory=True  # Speeds up data transfer to GPU\n)\n\n\n# Validation dataset without augmentation\nval_dataset = TripletPathsDataset(val_triplets, augment_prob=0.5)\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=128,  # Larger batch size\n    shuffle=True,\n    num_workers=8,  # Use multiple CPU workers\n    pin_memory=True  # Speeds up data transfer to GPU\n)","metadata":{"_uuid":"141058fa-37dd-4c28-910f-e1e8fbde570d","_cell_guid":"cee6ecae-e64a-4545-99ea-237e82dc8a16","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-24T06:42:26.899710Z","iopub.execute_input":"2024-11-24T06:42:26.900003Z","iopub.status.idle":"2024-11-24T06:42:26.906566Z","shell.execute_reply.started":"2024-11-24T06:42:26.899977Z","shell.execute_reply":"2024-11-24T06:42:26.905763Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision.models import mobilenet_v3_small\nimport torch.nn as nn\nimport torch\n\n# Load pre-trained MobileNetV3 Small\nmodel = mobilenet_v3_small(pretrained=True)\n\n# Replace the classifier with an embedding layer\nmodel.classifier = nn.Sequential(\n    nn.Linear(model.classifier[0].in_features, 128),  # Reduce to 128-dimensional embeddings\n    nn.ReLU()\n)\n\n\n# Move the model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)","metadata":{"_uuid":"06f8900e-8e28-43eb-83c4-1f53ba593e89","_cell_guid":"9b0d9b00-e9b3-4af1-b732-c141be1133d5","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-24T06:42:26.907775Z","iopub.execute_input":"2024-11-24T06:42:26.908098Z","iopub.status.idle":"2024-11-24T06:42:27.012151Z","shell.execute_reply.started":"2024-11-24T06:42:26.908062Z","shell.execute_reply":"2024-11-24T06:42:27.011379Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.optim as optim\n\n# Define the Triplet Margin Loss\ntriplet_loss = nn.TripletMarginLoss(margin=1.5)  # You can tweak the margin value\n\n# Define the optimizer\noptimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)","metadata":{"_uuid":"28d5d177-80b0-4b0a-a74f-57f1e1c1e38b","_cell_guid":"9868ee02-f513-4d5e-95db-d93988036b17","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-24T06:42:27.013237Z","iopub.execute_input":"2024-11-24T06:42:27.013514Z","iopub.status.idle":"2024-11-24T06:42:27.020636Z","shell.execute_reply.started":"2024-11-24T06:42:27.013484Z","shell.execute_reply":"2024-11-24T06:42:27.019524Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\n\n# Settings\nepochs = 3  # Run for 3 epochs\n\n# Start training\nfor epoch in range(epochs):\n    print(f\"Epoch {epoch + 1}/{epochs}\")\n    \n    # ---- Training Phase ----\n    model.train()  # Set model to training mode\n    total_train_loss = 0\n\n    # Wrap the train_loader with tqdm for progress tracking\n    train_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n    for anchor, positive, negative in train_bar:\n        # Move data to GPU if available\n        anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n\n        # Forward pass\n        anchor_embed = model(anchor)\n        positive_embed = model(positive)\n        negative_embed = model(negative)\n\n        # Compute loss\n        loss = triplet_loss(anchor_embed, positive_embed, negative_embed) + 0.1*torch.mean(torch.nn.functional.cosine_similarity(anchor_embed, negative_embed))  # Cosine similarity penalty\n\n        total_train_loss += loss.item()\n\n        # Backward pass and optimizer step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n       \n    # Compute average training loss\n    avg_train_loss = total_train_loss / len(train_loader)\n\n    # ---- Validation Phase ----\n    model.eval()  # Set model to evaluation mode\n    total_val_loss = 0\n\n    # Wrap the val_loader with tqdm for progress tracking\n    val_bar = tqdm(val_loader, desc=\"Validation\", leave=False)\n    with torch.no_grad():\n        for anchor, positive, negative in val_bar:\n            # Move data to GPU if available\n            anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n\n            # Forward pass\n            anchor_embed = model(anchor)\n            positive_embed = model(positive)\n            negative_embed = model(negative)\n\n            # Compute validation loss\n            loss = triplet_loss(anchor_embed, positive_embed, negative_embed)\n            total_val_loss += loss.item()\n\n            # Update the progress bar with the current loss\n            val_bar.set_postfix(loss=loss.item())\n\n    # Compute average validation loss\n    avg_val_loss = total_val_loss / len(val_loader)\n\n    # Display training and validation loss for the epoch\n    print(f\"Epoch {epoch + 1}/{epochs} - Training Loss: {avg_train_loss:.4f} - Validation Loss: {avg_val_loss:.4f}\")","metadata":{"_uuid":"f7e1ff23-492b-4e77-a163-6144d12d268e","_cell_guid":"45cd8ddd-ceba-4add-8378-6c516d7c559c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-24T06:42:27.022246Z","iopub.execute_input":"2024-11-24T06:42:27.022547Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save({\n    'epoch': epoch,\n    'model_state_dict': model.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n}, \"mobilenetv3_best_triplet.pth\")\ntorch.save(model.state_dict(), \"/kaggle/working/mobilenetv3_best_triplet.pth\")","metadata":{"_uuid":"c8618250-2847-40fd-a750-33bde370caa3","_cell_guid":"700dfee3-9d53-46a4-a467-0af26290e79c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torchvision.models as models\nfrom torch import nn\n\n# Redefine the model architecture to match your fine-tuned model\nfine_tuned_model = models.mobilenet_v3_small(pretrained=False)\nfine_tuned_model.classifier = nn.Sequential(\n    nn.Linear(fine_tuned_model.classifier[0].in_features, 128),  # Reduce to 128-dimensional embeddings\n    nn.ReLU()\n)\n\n# Load the saved weights\nfine_tuned_model.load_state_dict(torch.load(\"/kaggle/input/image-state/mobilenetv3_best_triplet.pth\", weights_only=True))\n\n# Move to device and set to evaluation mode\nfine_tuned_model = fine_tuned_model.to(device)\nfine_tuned_model.eval()\n\nnon_fine_tuned_model = mobilenet_v3_small(pretrained=True)\nnon_fine_tuned_model.classifier = nn.Sequential(\n    nn.Linear(non_fine_tuned_model.classifier[0].in_features, 128),  # Reduce to 128-dimensional embeddings\n    nn.ReLU()\n)\n\nnon_fine_tuned_model = non_fine_tuned_model.to(device)\nnon_fine_tuned_model.eval()","metadata":{"_uuid":"3f94a0d6-ac79-442c-8dcc-350e10b5a78d","_cell_guid":"698fbf26-603b-46a3-b284-d295cf572019","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\n\ndef evaluate_cosine_similarity(model, data_loader, device):\n    positive_similarities = []\n    negative_similarities = []\n\n    model.eval()\n    with torch.no_grad():\n        val_bar = tqdm(data_loader, desc=\"Embedding Triplets\", leave=False)\n        for anchor, positive, negative in val_bar:\n            anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n\n            anchor_embed = model(anchor).cpu().numpy()\n            positive_embed = model(positive).cpu().numpy()\n            negative_embed = model(negative).cpu().numpy()\n\n        for a, p, n in zip(anchor_embed, positive_embed, negative_embed):\n                positive_sim = cosine_similarity(a.reshape(1, -1), p.reshape(1, -1))[0][0]\n                negative_sim = cosine_similarity(a.reshape(1, -1), n.reshape(1, -1))[0][0]\n\n                positive_similarities.append(positive_sim)\n                negative_similarities.append(negative_sim)\n\n    # Compute average similarities\n    avg_positive_similarity = np.mean(positive_similarities)\n    avg_negative_similarity = np.mean(negative_similarities)\n    print(\"avg pos std dev :\" + str(np.std(positive_similarities)))\n    print(\"avg neg std dev :\" + str(np.std(negative_similarities)))\n\n\n    return avg_positive_similarity, avg_negative_similarity\n\n# Evaluate fine-tuned model\nprint(\"Evaluating Fine-Tuned Model...\")\nfine_tuned_positive_sim, fine_tuned_negative_sim = evaluate_cosine_similarity(fine_tuned_model, val_loader, device)\nprint(f\"Fine-Tuned Model - Avg Positive Cosine Sim: {fine_tuned_positive_sim:.4f}, Avg Negative Cosine Sim: {fine_tuned_negative_sim:.4f}\")\n\n# Evaluate non-fine-tuned model\nprint(\"Evaluating Non-Fine-Tuned Model...\")\nnon_fine_tuned_positive_sim, non_fine_tuned_negative_sim = evaluate_cosine_similarity(non_fine_tuned_model, val_loader, device)\nprint(f\"Non Fine-Tuned Model - Avg Positive Cosine Sim: {non_fine_tuned_positive_sim:.4f}, Avg Negative Cosine Sim: {non_fine_tuned_negative_sim:.4f}\")","metadata":{"_uuid":"e1a22427-c8c8-4497-a37c-6775980a9f6d","_cell_guid":"9d6a773e-c044-4084-8691-1d8f8b2b3502","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}