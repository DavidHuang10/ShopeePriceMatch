{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":24286,"databundleVersionId":1878097,"sourceType":"competition"},{"sourceId":9997048,"sourceType":"datasetVersion","datasetId":6152995},{"sourceId":176770,"sourceType":"modelInstanceVersion","modelInstanceId":150548,"modelId":173027}],"dockerImageVersionId":30787,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport tqdm\nimport torchvision.models as models\nimport pandas as pd\nimport numpy as np\nfrom torch import nn\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom sentence_transformers import SentenceTransformer\n# Image Preprocessing\nimage_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Fine-Tuned MobileNetV3 Model\nclass FineTunedMobileNetV3(nn.Module):\n    def __init__(self, fc_dim=128):\n        super().__init__()\n        self.backbone = models.mobilenet_v3_small(pretrained=False)\n        in_features = self.backbone.classifier[0].in_features  # Access in_features directly\n        self.backbone.classifier = nn.Sequential(\n            nn.Linear(in_features, fc_dim),\n            nn.ReLU()\n        )\n\n    def forward(self, images):\n        return self.backbone(images)\n\n# Dataset for Images\nclass ShopeeTestImageDataset(Dataset):\n    def __init__(self, image_paths, transform):\n        self.image_paths = image_paths\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n        return self.transform(image)\n\n# Functions for Embedding Generation\ndef get_image_embeddings(image_paths, model, transform, batch_size=32):\n    model.eval()\n    dataset = ShopeeTestImageDataset(image_paths, transform)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n    embeddings = []\n    with torch.no_grad():\n        for images in tqdm(dataloader, desc=\"Generating Image Embeddings\", unit=\"batch\"):\n            images = images.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n            embedding = model(images).cpu().numpy()\n            embeddings.append(embedding)\n    return np.vstack(embeddings)\n\n# Predict Matches in Batches\ndef predict_image_matches(image_embeddings, threshold=0.75, batch_size=1000):\n    matches = {}\n    num_embeddings = len(image_embeddings)\n\n    for start in tqdm(range(0, num_embeddings, batch_size), desc=\"Predicting Matches in Batches\", unit=\"batch\"):\n        end = min(start + batch_size, num_embeddings)\n        batch_sim = cosine_similarity(image_embeddings[start:end], image_embeddings)\n\n        for i, sim_vector in enumerate(batch_sim):\n            match_indices = set(np.where(sim_vector >= threshold)[0])\n            matches[start + i] = match_indices\n\n    return matches\n\n# Load Fine-Tuned Model\ncnn_model = FineTunedMobileNetV3().backbone.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ncnn_model.load_state_dict(torch.load(\"/kaggle/input/image-state/mobilenetv3_best_triplet.pth\", weights_only=True))\ncnn_model.eval()\n\n# Load Data\n#CHANGE HERE\ntest_df = pd.read_csv(\"/kaggle/input/shopee-product-matching/test.csv\")\nimage_paths = [f\"/kaggle/input/shopee-product-matching/test_images/{img}\" for img in test_df[\"image\"]]\nprint('loaded data')\n\n# Generate Embeddings\nimage_embeddings = get_image_embeddings(image_paths, cnn_model, image_transform, batch_size=32)\n\n# Predict Matches\nmatches = predict_image_matches(image_embeddings, threshold=0.95, batch_size=1000)\n\n# Prepare Submission\ndef prepare_submission(test_df, matches):\n    match_list = [\" \".join(test_df.loc[list(match), \"posting_id\"].values) for match in matches.values()]\n    test_df[\"image_matches\"] = match_list\n\nprepare_submission(test_df, matches)","metadata":{"_uuid":"caeaadbb-101c-4e9d-93f5-879293b18ff8","_cell_guid":"0cad8291-73d9-420f-a17b-3fc318396852","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-22T20:00:35.348882Z","iopub.execute_input":"2025-01-22T20:00:35.349203Z","iopub.status.idle":"2025-01-22T20:00:44.767876Z","shell.execute_reply.started":"2025-01-22T20:00:35.349174Z","shell.execute_reply":"2025-01-22T20:00:44.766755Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Paths\ntest_csv_path = '/kaggle/input/shopee-product-matching/test.csv'\ntext_model_path = '/kaggle/input/xlm/pytorch/fine-tuned/1/fine_tuned_model/'\n\n\n# Preprocess text: Remove casing (convert to lowercase)\n#test_df['title'] = test_df['title'].str.lower()\n\n# Load SentenceTransformer model\ntuned_xlm = SentenceTransformer(text_model_path).to(device)\n\n# Generate text embeddings in batches\ndef generate_text_embeddings(df, batch_size=32):\n    \"\"\"\n    Generates text embeddings for a DataFrame using the SentenceTransformer model.\n    \"\"\"\n    titles = df['title'].tolist()\n    embeddings = []\n    \n    # Batch processing for text embeddings\n    for i in tqdm(range(0, len(titles), batch_size), desc=\"Generating text embeddings\"):\n        batch_titles = titles[i:i + batch_size]\n        batch_embeddings = tuned_xlm.encode(batch_titles, batch_size=batch_size, show_progress_bar=False, device=device)\n        embeddings.extend(batch_embeddings)\n    \n    # Create a dictionary of embeddings\n    text_embeddings = {posting_id: emb for posting_id, emb in zip(df['posting_id'], embeddings)}\n    return text_embeddings\n\n# Generate text embeddings\nprint(\"Generating text embeddings...\")\ntext_embeddings = generate_text_embeddings(test_df, batch_size=64)\n\n# Ensure embeddings are mapped correctly\ntest_df['text_embedding'] = test_df['posting_id'].map(text_embeddings)\n\n# Check for missing embeddings and handle gracefully\nif test_df['text_embedding'].isnull().any():\n    print(\"Warning: Missing embeddings detected. Dropping rows with missing embeddings.\")\ntest_df = test_df.dropna(subset=['text_embedding']).reset_index(drop=True)\n\n# Batch cosine similarity calculation for memory efficiency\ndef compute_similarity_batched(embeddings, batch_size=512):\n    \"\"\"\n    Computes cosine similarity in batches for memory efficiency.\n    \"\"\"\n    num_items = len(embeddings)\n    similarity_matrix = np.zeros((num_items, num_items), dtype=np.float32)\n\n    # Compute pairwise similarity in batches\n    for start in tqdm(range(0, num_items, batch_size), desc=\"Computing similarity\"):\n        end = min(start + batch_size, num_items)\n        batch_embeddings = embeddings[start:end]\n        similarity_matrix[start:end] = cosine_similarity(batch_embeddings, embeddings)\n    \n    return similarity_matrix\n\n# Prepare text embeddings as an array\ntext_emb_array = np.stack(test_df['text_embedding'].values)\n\n# Compute text similarity in batches\nprint(\"Computing text similarity...\")\ntext_similarity = compute_similarity_batched(text_emb_array, batch_size=512)\n\n# Generate matches for submission\ndef generate_submission(df, similarity_matrix, threshold=0.85):\n    \"\"\"\n    Generates submission data in the required format for Kaggle.\n    \"\"\"\n    posting_ids = df['posting_id'].tolist()\n    matches = []\n    \n    for idx in tqdm(range(len(posting_ids)), desc=\"Generating matches for submission\"):\n        # Find matches for the current posting ID\n        matched_indices = np.where(similarity_matrix[idx] >= threshold)[0]\n        matched_ids = [posting_ids[i] for i in matched_indices]\n        matches.append(\" \".join(matched_ids))\n    \n    # Add matches to DataFrame\n    df['matches'] = matches\n    return df[['posting_id', 'matches']]\n\n# Generate submission DataFrame\nsubmission_df = generate_submission(test_df, text_similarity, threshold=0.9)\n\ntest_df","metadata":{"_uuid":"e67e1304-d933-4b97-8d6b-058b4f620510","_cell_guid":"315f6a7d-5ba1-49be-b821-d27b1ec50530","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-22T20:00:49.861171Z","iopub.execute_input":"2025-01-22T20:00:49.861508Z","iopub.status.idle":"2025-01-22T20:01:00.844358Z","shell.execute_reply.started":"2025-01-22T20:00:49.861477Z","shell.execute_reply":"2025-01-22T20:01:00.843557Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def merge_and_clean(row):\n    # Combine lists from 'matches' and 'image_matches'\n    combined = set(row['matches'].split() + row['image_matches'].split())\n    # Convert the set back to list\n    return \" \".join(list(combined))\n\n# Apply the function to each row in the DataFrame\ntest_df['matches'] = test_df.apply(merge_and_clean, axis=1)","metadata":{"_uuid":"fdcd80be-494d-4844-b2b4-1db2d3906b66","_cell_guid":"80b4673e-dcd3-45fb-8742-ebbfa7d75b40","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-22T20:01:13.654387Z","iopub.execute_input":"2025-01-22T20:01:13.655230Z","iopub.status.idle":"2025-01-22T20:01:13.660551Z","shell.execute_reply.started":"2025-01-22T20:01:13.655193Z","shell.execute_reply":"2025-01-22T20:01:13.659724Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save to CSV\nsubmission_df = test_df[[\"posting_id\",\"matches\"]]\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"_uuid":"56b210f6-7098-4311-b1cc-8bc4bd24f330","_cell_guid":"9f81d55d-2894-4f66-8006-c2d177ec3b18","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-22T20:01:15.974374Z","iopub.execute_input":"2025-01-22T20:01:15.974763Z","iopub.status.idle":"2025-01-22T20:01:15.984236Z","shell.execute_reply.started":"2025-01-22T20:01:15.974730Z","shell.execute_reply":"2025-01-22T20:01:15.983494Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}